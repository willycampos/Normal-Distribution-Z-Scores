{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+nFV9lMo2G+0RAKLn1Zyt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/willycampos/Normal-Distribution-Z-Scores/blob/main/normal_distribution_zscores.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uH4gIJLm37Jm",
        "outputId": "ad846782-1d38-407f-d995-4f73c1391507"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Z-score: 1.62 | Percentil: 94.8%\n",
            "Puntaje mínimo para bono: 83.29\n",
            "Porcentaje entre 70 y 85: 62.84%\n"
          ]
        }
      ],
      "source": [
        "# Ejercicio 1: Employee Performance (Distribución Normal)\n",
        "from scipy import stats\n",
        "\n",
        "perf_mean = 75\n",
        "perf_std = 8\n",
        "\n",
        "# 1. Crear el objeto de distribución normal\n",
        "perf_dist = stats.norm(loc=perf_mean, scale=perf_std)\n",
        "\n",
        "# 2. Z-score y Percentil para score de 88\n",
        "score = 88\n",
        "z_score = (score - perf_mean) / perf_std\n",
        "percentile = perf_dist.cdf(score)  # Cumulative Distribution Function\n",
        "\n",
        "print(f\"Z-score: {z_score:.2f} | Percentil: {percentile*100:.1f}%\")\n",
        "\n",
        "# 3. Top 15% para bonos (buscamos el valor que deja el 85% atrás)\n",
        "# Usamos Percent Point Function (la inversa de la CDF)\n",
        "min_score = perf_dist.ppf(0.85)\n",
        "print(f\"Puntaje mínimo para bono: {min_score:.2f}\")\n",
        "\n",
        "# 4. Porcentaje entre 70 y 85\n",
        "prob_70_85 = perf_dist.cdf(85) - perf_dist.cdf(70)\n",
        "print(f\"Porcentaje entre 70 y 85: {prob_70_85*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejercicio 2: Diferentes Escalas (Z-scores)\n",
        "# Alice: Test A (500, 100) score 650\n",
        "z_alice = (650 - 500) / 100\n",
        "\n",
        "# Bob: Test B (25, 5) score 33\n",
        "z_bob = (33 - 25) / 5\n",
        "\n",
        "print(f\"Z-Alice: {z_alice} | Z-Bob: {z_bob}\")\n",
        "\n",
        "# Comparación y percentiles\n",
        "better = \"Alice\" if z_alice > z_bob else \"Bob\"\n",
        "p_alice = stats.norm.cdf(z_alice)\n",
        "p_bob = stats.norm.cdf(z_bob)\n",
        "\n",
        "print(f\"Mejor rendimiento relativo: {better}\")\n",
        "print(f\"Percentil Alice: {p_alice*100:.1f}% | Percentil Bob: {p_bob*100:.1f}%\")"
      ],
      "metadata": {
        "id": "3PslMEML4XLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejercicio 3: Quality Control (Control de Procesos)\n",
        "bolt_mean = 10\n",
        "bolt_std = 0.2\n",
        "\n",
        "# 1. % de rechazo (Fuera de 9.6 y 10.4)\n",
        "# Probabilidad de estar dentro:\n",
        "p_dentro = stats.norm.cdf(10.4, bolt_mean, bolt_std) - stats.norm.cdf(9.6, bolt_mean, bolt_std)\n",
        "p_rechazo = 1 - p_dentro\n",
        "print(f\"Porcentaje de rechazo: {p_rechazo*100:.2f}%\")\n",
        "print(f\"Rechazados en 10,000 pernos: {int(p_rechazo * 10000)}\")\n",
        "\n",
        "# 2. Reducir rechazo al 1% (0.5% en cada cola)\n",
        "# Buscamos el Z que corresponde a un área acumulada de 0.995\n",
        "z_objetivo = stats.norm.ppf(0.995)\n",
        "# Despejamos std de la fórmula Z = (X - mu) / sigma -> sigma = (X - mu) / Z\n",
        "nuevo_std = (10.4 - bolt_mean) / z_objetivo\n",
        "print(f\"Desviación estándar necesaria para 1% de rechazo: {nuevo_std:.4f}mm\")"
      ],
      "metadata": {
        "id": "wFYLNuqO4XYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejercicio 4: Standardizing a Dataset (Puntajes Compuestos)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Datos\n",
        "np.random.seed(42)\n",
        "customers = pd.DataFrame({\n",
        "    'customer_id': range(1, 51),\n",
        "    'purchase_amount': np.random.normal(150, 40, 50),\n",
        "    'visits_per_month': np.random.normal(8, 3, 50),\n",
        "    'satisfaction_score': np.random.normal(4.2, 0.5, 50)\n",
        "})\n",
        "\n",
        "# 1. Estandarizar\n",
        "cols = ['purchase_amount', 'visits_per_month', 'satisfaction_score']\n",
        "for col in cols:\n",
        "    customers[f'{col[:4]}_z'] = (customers[col] - customers[col].mean()) / customers[col].std()\n",
        "\n",
        "# 2. Score compuesto y Top 5\n",
        "z_cols = ['purc_z', 'visi_z', 'sati_z']\n",
        "customers['composite_score'] = customers[z_cols].mean(axis=1)\n",
        "print(\"\\nTop 5 Clientes:\")\n",
        "print(customers.nlargest(5, 'composite_score')[['customer_id', 'composite_score']])\n",
        "\n",
        "# 3. Outliers (Z > 2 o Z < -2)\n",
        "outliers = customers[(customers[z_cols].abs() > 2).any(axis=1)]\n",
        "print(f\"\\nClientes inusuales detectados: {len(outliers)}\")"
      ],
      "metadata": {
        "id": "4AwLwFJR4XmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejercicio 5: Checking for Normality (Pruebas de Hipótesis)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "datasets = {\n",
        "    \"Normal\": np.random.normal(50, 10, 500),\n",
        "    \"Sesgada\": np.random.exponential(10, 500),\n",
        "    \"Bimodal\": np.concatenate([np.random.normal(30, 2, 250), np.random.normal(70, 2, 250)])\n",
        "}\n",
        "\n",
        "for name, data in datasets.items():\n",
        "    # 1. Visualización\n",
        "    plt.hist(data, bins=30, alpha=0.7)\n",
        "    plt.title(f\"Distribución {name}\")\n",
        "    plt.show()\n",
        "\n",
        "    # 2. Skewness\n",
        "    sk = stats.skew(data)\n",
        "\n",
        "    # 3. Test de Shapiro-Wilk (p-value > 0.05 significa que es Normal)\n",
        "    W, p_value = stats.shapiro(data)\n",
        "\n",
        "    is_normal = \"Sí\" if p_value > 0.05 else \"No\"\n",
        "    print(f\"Dataset {name:7} | Skewness: {sk:5.2f} | Shapiro p-value: {p_value:5.4f} | ¿Es Normal? {is_normal}\")"
      ],
      "metadata": {
        "id": "lxyH22Ex4X34"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}